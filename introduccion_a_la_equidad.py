# -*- coding: utf-8 -*-
"""Introduccion a la equidad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LuY0vu5z4-7UNvlRx2mwYSw4e_TQEJj8

# Introducción a la equidad

***Cristhian Alexander Torres Polanco***

**Revisión de Sesgos**

En el presente contenido revisaremos si el dataset prueba de siguiente ejercicio posee sesgos que favorescan o discriminen a una población.

**Conjuto de datos sobre Diabetes**

El conjunto de datos objeto de prueba se extrae de la pagina **Kaggle**, en cual es una recopilación de datos que proviene del instituto nacional de Diabetes y Enfermedades Digestivas y Renales de la India. La fecha de recepción de los datos es **9 de mayo de 1990** y es compone 768 observaciones, 8 caracteristicas y una clase.

Enlace del data set: https://www.kaggle.com/datasets/mathchi/diabetes-data-set

**Descripcion del data set**

El contenido del conjuto de datos se refiere a observaciones de pacientes, todas mujeres, entre los 21 a 81 años de edad de ascedencia india Pima.

**Caracteristicas:**
* Pregnancies: Número de veces que está embarazada
* Glucose: Concentración de glucosa plasmática a las 2 horas en una prueba de tolerancia oral a la glucosa
* BloodPressure: presión arterial diastólica (mm Hg)
* SkinThickness: Grosor del pliegue cutáneo del tríceps (mm)
* Insulin: insulina sérica de 2 horas (mu U/ml)
* BMI: índice de masa corporal (peso en kg/(altura en m)^2)
* DiabetesPedigreeFunction: Función de pedigrí de diabetes
* Age: Edad (años)

**Target u Objetivo**

El target se representa por el campo **Outcome** que contiene valores de 1 y 0; los cuales describen 1 para positivo (paciente con diabetes) y 0 negativo (paciente sin diabetis)

**Análisis exploratorio del conjunto de Datos**

1. Se cargan los datos y las librerías de uso. Se evidencia que todos los campos son tipo número.
"""

# Carga de Libreria
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics

# Cargar datos
url = ('https://docs.google.com/spreadsheets/d/e/2PACX-1vR4xZc5jF801GkS94a0YFws0vweUOKCrHc_8O22JPlCPKWw4d7dlVlOHDpq0oZ70iOx2ztb_0ZVestE/pub?output=csv')
df = pd.read_csv(url)
# Encabesado
print(df.shape)
df.info()

df.head()

"""2. Se verifican Observaciones duplicadas, para este caso, no tenemos duplicidad"""

df.duplicated()

"""3. Se valida si tenemos campos nulos, para este dataset no tenemos datos vacíos"""

df.isnull().sum()

"""4. Se detalla la descripción estadístca del conjunto de datos. Se observa que las caracteristicas Glucose, BloodPressure, SkinThickness, Insulin y BMI están sospechosaente en 0, lo que infiere a error en la toma de datos o que se realizó previamente transformación de nulls a cero."""

df.describe()

"""4.1 Se confirma valores en cero. Son una muestra significativa del data set por lo cual no se eliminan, pero afetaran considerablemente el resultado de culaquier modelo de ML."""

print('# de valores en 0 de la Glucose: ',df[df['Glucose']==0].shape[0])
print('# de valores en 0 de la BloodPressure: ',df[df['BloodPressure']==0].shape[0])
print('# de valores en 0 de la SkinThickness: ',df[df['SkinThickness']==0].shape[0])
print('# de valores en 0 de la Insulin: ',df[df['Insulin']==0].shape[0])
print('# de valores en 0 de la BMI: ',df[df['BMI']==0].shape[0])

"""4.2 **Desbalance del Data Set:** Se ve un marcado desbalance del data set, aproximadamente de 60% del conjunto de datos es de resultados negativos. Lo que nos anticipa que un podelo de machine learning supervisado clasificara mejor a los pacientes con resultados negativos."""

dfClases = pd.DataFrame(index = ['Positivo', 'Negativo'])
valores = [df[df['Outcome']==1].shape[0],df[df['Outcome']==0].shape[0]]
print(valores)
dfClases['valores'] = valores
dfClases.plot(kind = 'bar')

"""4.3 **Comportamiento del data set:** En el siguiente gráfico se puede notar el comportamiento de cada característica con respeto al resultado. Se puede observar que Edad tiene tendencia a mujeres jóvenes con resultados positivos y los resultados negativos no tienen una separabilidad marcada."""

#Creación de historigramas para validar gaussanidad y separación de las clases por cada característica.
columns = df.columns[:-1]
f, ax = plt.subplots(3, 3, figsize = (10,10))
ax = ax.ravel()
for i, col in enumerate(columns):
  ax[i] = sns.histplot(data = df, x = col, hue = 'Outcome', kde = True, bins = 30, ax = ax[i])
  ax[i].set_xlabel(col)
  ax[i].set_xlabel('Resultado')
  ax[i].set_title(f'{col}')
  ax[i].legend(title = 'Clase', labels = ['0','1'])
plt.tight_layout()
plt.show()

"""4.4 **Correlación de Caracteristicas con resultados:** Se evidencia que las tres características más influyentes son Glucosa, BMI y AGE."""

sns.set(rc={'figure.figsize': (20,10)})
sns.heatmap(df.corr(), annot=True, cmap="YlGnBu")

"""5. **Entrenamiento del Modelo:** Se entrena el modelo de regresión logistíca con parametros por Defoult. Para ello, se escala el data set con el objetivo de mejorar en desempeño de la regresión."""

#Separación de la data train y test

X = df.drop(columns=['Outcome'])
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#Se escala el dataset:
scaler = StandardScaler()
xTrainScaler = scaler.fit_transform(X_train)
xTestScaler = scaler.fit_transform(X_test)

"""5.1.**Exactitud del Modelo:**  El modelo sin hiperparametros ajustados efectua el 0.736 de exactitud. El desempeño no es el mejor."""

# Se carga el modelo Regresión Logística
logistica = LogisticRegression()
# Se entrena el modelo
logistica.fit(xTrainScaler, y_train)
# Se obtiene el accurancy
print(logistica.score(xTestScaler, y_test))

"""6. **Matriz de confusión:** la matriz hace una comparación entre los valores predecidos y los valores reales. Se divide de la siguiente forma:

Se debe tener pressente que en el ejercicio. Las personas con diagnostico 0 son negativas para diabetes y con 1 para las personas que tienen diabetes.

* Verdaderos Positivos: Personas que son negativas para diabetes y el modelo las clasificó como negativas. (Siguente gráfico: Superior Izquierdo)
* Verdaderon negativo: Personas que son positivas para diabetes y el modelo las clasificó como positivas. (Siguente gráfico: Inferior derecho)
* Falso negativo: Personas que son negativo para diabetes y el modelo las clasificó como positivas. (Siguente gráfico: Inferior izquierdo)
* Falso Positivo: Personas que son positivas para diabetes y el modelo las clasificó como Negativo. (Siguente gráfico: Superior Derecho)

En este caso se observa que el modelo tiene mayor efectividad para clasificar los Negativos que los positivos.
"""

# Tamaño de la matriz
f, a = plt.subplots(figsize=(6, 3))
# Cargar y evaluar la matriz de confusión de acuerdo al modelo y data de prueba.
metrics.ConfusionMatrixDisplay.from_estimator(logistica, xTestScaler, y_test, cmap=plt.cm.Blues, ax=a)

"""7. **Conclusión:**

Se enomeran las conclusiones del ejercicio de introduicción a la equidad:

1.	En el data set no se encontraron observaciones duplicadas, tampoco datos vacíos. Pero se detallan valores en cero atípicos que afectan el desempeño del modelo (numeral 4.1).
2.	Se observa un desbalance del conjunto de datos; 60% de las observaciones son negativas, lo que influye a la clasificación (numeral 4.2).
3.	Se detalla que el data set está sesgado en el campo edad: tiene tendencia a mujeres jóvenes con resultados positivos (numeral 4.3).
4.	Las características que aportan más al resultado del modelo son Glucosa, BMI y AGE. Pero glucosa e BMI, tiene observaciones en cero (numeral 4.4).

Se concluye que el modelo puede estar sesgado por el desbalance de conjunto de datos y la proporción de edades en las muestras, además, los datos en cero dejan un desempeño pobre del modelo de clasificación.

"""

